\contentsline {section}{\numberline {1}2014-06-03 Channel Estimation}{4}{section.1}
\contentsline {subsection}{\numberline {1.1}Problem Statement:}{4}{subsection.1.1}
\contentsline {subsection}{\numberline {1.2}Solution:}{4}{subsection.1.2}
\contentsline {subsection}{\numberline {1.3}Multiple Copies of Y}{4}{subsection.1.3}
\contentsline {section}{\numberline {2}Another L[X$|$Y]}{4}{section.2}
\contentsline {section}{\numberline {3}Notes from Kalman Filter Wikipedia}{4}{section.3}
\contentsline {section}{\numberline {4}2014-06-05}{4}{section.4}
\contentsline {subsection}{\numberline {4.1}Q1}{4}{subsection.4.1}
\contentsline {subsection}{\numberline {4.2}Q2}{4}{subsection.4.2}
\contentsline {subsection}{\numberline {4.3}Q3}{4}{subsection.4.3}
\contentsline {subsection}{\numberline {4.4}Q4}{5}{subsection.4.4}
\contentsline {subsection}{\numberline {4.5}Q5}{5}{subsection.4.5}
\contentsline {section}{\numberline {5}Notes from EE126 Appendix A}{5}{section.5}
\contentsline {section}{\numberline {6}Proofs about L[X$|$Y]}{5}{section.6}
\contentsline {subsection}{\numberline {6.1}L[X$|$Y,Z] = L[X$|$Y] + L[X$|$Z]}{5}{subsection.6.1}
\contentsline {subsection}{\numberline {6.2}L[X$|$Y,Z] = L[X$|$Y] + L[X$|$Z-L[Z$|$Y]]}{5}{subsection.6.2}
\contentsline {section}{\numberline {7}2014-06-09\nobreakspace {}2014-06-15 Kalman Filter}{5}{section.7}
\contentsline {subsection}{\numberline {7.1}Problem Setup:}{5}{subsection.7.1}
\contentsline {subsection}{\numberline {7.2}Goal:}{5}{subsection.7.2}
\contentsline {subsection}{\numberline {7.3}Equations:}{5}{subsection.7.3}
\contentsline {subsection}{\numberline {7.4}$\mathbb {E}[X[n+1]|Y^{n-1}]$}{5}{subsection.7.4}
\contentsline {subsection}{\numberline {7.5}$\mathbb {E}[Y[n]|Y^{n-1}]$}{5}{subsection.7.5}
\contentsline {subsection}{\numberline {7.6}$\mathbb {E}[X[n+1]|Y[n]-C\mathaccentV {hat}05E{X}[n]]$}{5}{subsection.7.6}
\contentsline {section}{\numberline {8}2014-06-16 Underlying X1 and X2}{6}{section.8}
\contentsline {subsection}{\numberline {8.1}Problem Setup}{6}{subsection.8.1}
\contentsline {subsection}{\numberline {8.2}Solution}{6}{subsection.8.2}
\contentsline {section}{\numberline {9}2014-06-18 Conditions of Observability}{6}{section.9}
\contentsline {section}{\numberline {10}2014-06-19 Various Proofs}{6}{section.10}
\contentsline {subsection}{\numberline {10.1}Best Control}{6}{subsection.10.1}
\contentsline {subsection}{\numberline {10.2}Error of Control Problem}{7}{subsection.10.2}
\contentsline {subsection}{\numberline {10.3}Without System Error, Estimation Error = 0}{7}{subsection.10.3}
\contentsline {section}{\numberline {11}2014-06-29 Kalman Filter with Multiplicative Noise}{7}{section.11}
\contentsline {subsection}{\numberline {11.1}Problem Setup:}{7}{subsection.11.1}
\contentsline {subsection}{\numberline {11.2}Goal:}{7}{subsection.11.2}
\contentsline {subsection}{\numberline {11.3}Equations:}{7}{subsection.11.3}
\contentsline {subsection}{\numberline {11.4}$\mathbb {E}[X[n]|Y^{n-1}]$}{7}{subsection.11.4}
\contentsline {subsection}{\numberline {11.5}$\mathbb {E}[Y[n]|Y^{n-1}]$}{7}{subsection.11.5}
\contentsline {subsection}{\numberline {11.6}$\mathbb {E}[X[n]|Y[n]-CM(n)A\mathaccentV {hat}05E{X}[n-1]]$}{7}{subsection.11.6}
\contentsline {section}{\numberline {12}Notes from A Mathematical Theory of Communication}{8}{section.12}
\contentsline {subsubsection}{\numberline {12.0.1}Introduction}{8}{subsubsection.12.0.1}
\contentsline {subsection}{\numberline {12.1}Discrete Noiseless Systems}{8}{subsection.12.1}
\contentsline {subsubsection}{\numberline {12.1.1}The Discrete Noiseless Channel}{8}{subsubsection.12.1.1}
\contentsline {subsubsection}{\numberline {12.1.2}The Discrete Source of Information}{8}{subsubsection.12.1.2}
\contentsline {subsubsection}{\numberline {12.1.3}The Series of Approximations to English}{8}{subsubsection.12.1.3}
\contentsline {subsubsection}{\numberline {12.1.4}Graphical Representation of a Markoff (Markov?) Process}{9}{subsubsection.12.1.4}
\contentsline {subsubsection}{\numberline {12.1.5}Ergodic and Mixed Sources}{9}{subsubsection.12.1.5}
\contentsline {subsubsection}{\numberline {12.1.6}Choice, Uncertainty and Entropy}{9}{subsubsection.12.1.6}
\contentsline {subsubsection}{\numberline {12.1.7}The Entropy of an Information Source}{9}{subsubsection.12.1.7}
\contentsline {subsubsection}{\numberline {12.1.8}Representations of the Encoding and Decoding Operations}{10}{subsubsection.12.1.8}
\contentsline {subsubsection}{\numberline {12.1.9}The Fundamental Theorem for a Noiseless Channel}{10}{subsubsection.12.1.9}
\contentsline {subsubsection}{\numberline {12.1.10}Discussion and Examples}{10}{subsubsection.12.1.10}
\contentsline {subsection}{\numberline {12.2}Discrete Noisy Systems}{10}{subsection.12.2}
\contentsline {subsubsection}{\numberline {12.2.1}Representation of a Noisy Discrete Channel}{10}{subsubsection.12.2.1}
\contentsline {subsubsection}{\numberline {12.2.2}Equivocation and Channel Capacity}{10}{subsubsection.12.2.2}
\contentsline {subsubsection}{\numberline {12.2.3}The Fundamental Theorem for a Discrete Channel with Noise}{10}{subsubsection.12.2.3}
\contentsline {subsubsection}{\numberline {12.2.4}Discussion}{10}{subsubsection.12.2.4}
\contentsline {subsubsection}{\numberline {12.2.5}Example of a Discrete Channel and its Capacity}{10}{subsubsection.12.2.5}
\contentsline {subsubsection}{\numberline {12.2.6}The Channel Capacity in Certain Special Cases}{10}{subsubsection.12.2.6}
\contentsline {subsubsection}{\numberline {12.2.7}An Example of Efficient Coding}{11}{subsubsection.12.2.7}
\contentsline {section}{\numberline {13}Yury Polyanskiy: Channel Coding Rate in the Finite Blocklength Regime}{11}{section.13}
\contentsline {section}{\numberline {14}Cover and Thomas: Information Theory}{11}{section.14}
\contentsline {subsection}{\numberline {14.1}Chapter 1: Introduction and Preview}{11}{subsection.14.1}
\contentsline {subsection}{\numberline {14.2}Chapter 2: Entropy and Mutual Information}{11}{subsection.14.2}
\contentsline {subsubsection}{\numberline {14.2.1}Entropy}{11}{subsubsection.14.2.1}
\contentsline {subsubsection}{\numberline {14.2.2}Joint and Conditional Entropy}{11}{subsubsection.14.2.2}
\contentsline {subsubsection}{\numberline {14.2.3}Relative Entropy and Mutual Information}{11}{subsubsection.14.2.3}
\contentsline {subsubsection}{\numberline {14.2.4}Relationship between Entropy and Mutual Information}{11}{subsubsection.14.2.4}
\contentsline {subsubsection}{\numberline {14.2.5}Chain Rules}{12}{subsubsection.14.2.5}
\contentsline {section}{\numberline {15}2014-07-14\nobreakspace {}2014-07-21 Kalman Filter Learning Crand}{12}{section.15}
\contentsline {section}{\numberline {16}Results of Simulations}{13}{section.16}
\contentsline {subsection}{\numberline {16.1}Kalman Filter Additive Noise}{13}{subsection.16.1}
\contentsline {subsection}{\numberline {16.2}Kalman Filter Ignoring Multiplicative Noise}{14}{subsection.16.2}
\contentsline {subsection}{\numberline {16.3}Kalman Filter for Multiplicative Noise}{15}{subsection.16.3}
\contentsline {subsection}{\numberline {16.4}Quantization Noise: Schenato}{16}{subsection.16.4}
\contentsline {subsection}{\numberline {16.5}NonCoherence Estimation: Gireeja}{17}{subsection.16.5}
\contentsline {subsection}{\numberline {16.6}NonCoherence Control: Gireeja}{18}{subsection.16.6}
\contentsline {subsection}{\numberline {16.7}Varying A, NonCoherence Control, Gireeja}{18}{subsection.16.7}
\contentsline {subsection}{\numberline {16.8}Rajasekaran vs Schenato: Prediction vs Estimation}{18}{subsection.16.8}
\contentsline {subsection}{\numberline {16.9}Delay Estimation: Quant Noise, No Drops}{19}{subsection.16.9}
\contentsline {subsubsection}{\numberline {16.9.1}State Noise}{21}{subsubsection.16.9.1}
\contentsline {subsubsection}{\numberline {16.9.2}Channel Additive Noise}{21}{subsubsection.16.9.2}
\contentsline {subsubsection}{\numberline {16.9.3}Multiplicative Noise}{23}{subsubsection.16.9.3}
\contentsline {subsection}{\numberline {16.10}Delay Estimation: Quant Noise + Packet Drops}{24}{subsection.16.10}
\contentsline {subsubsection}{\numberline {16.10.1}State Noise}{27}{subsubsection.16.10.1}
\contentsline {subsubsection}{\numberline {16.10.2}Channel Additive Noise}{28}{subsubsection.16.10.2}
\contentsline {subsubsection}{\numberline {16.10.3}Quantization Noise}{29}{subsubsection.16.10.3}
\contentsline {subsection}{\numberline {16.11}Gireeja's Control}{29}{subsection.16.11}
\contentsline {subsubsection}{\numberline {16.11.1}State Noise}{31}{subsubsection.16.11.1}
\contentsline {subsubsection}{\numberline {16.11.2}Additive Noise}{32}{subsubsection.16.11.2}
\contentsline {subsection}{\numberline {16.12}Delay Control: Quantization Noise, No Drops}{32}{subsection.16.12}
\contentsline {subsubsection}{\numberline {16.12.1}A $<$ 1}{32}{subsubsection.16.12.1}
\contentsline {subsubsection}{\numberline {16.12.2}State Noise}{38}{subsubsection.16.12.2}
\contentsline {subsubsection}{\numberline {16.12.3}Additive Noise}{39}{subsubsection.16.12.3}
\contentsline {subsubsection}{\numberline {16.12.4}A $>$ 1}{39}{subsubsection.16.12.4}
\contentsline {subsection}{\numberline {16.13}Delay Control: Quant Noise, Packet Drops}{41}{subsection.16.13}
\contentsline {subsubsection}{\numberline {16.13.1}Theoretical Curves}{42}{subsubsection.16.13.1}
\contentsline {subsubsection}{\numberline {16.13.2}State Noise}{44}{subsubsection.16.13.2}
\contentsline {subsubsection}{\numberline {16.13.3}Additive Noise}{44}{subsubsection.16.13.3}
\contentsline {subsubsection}{\numberline {16.13.4}Threshold of Stability}{45}{subsubsection.16.13.4}
\contentsline {subsubsection}{\numberline {16.13.5}Varying Drop Probability}{46}{subsubsection.16.13.5}
\contentsline {subsubsection}{\numberline {16.13.6}Varying Delay}{47}{subsubsection.16.13.6}
\contentsline {subsubsection}{\numberline {16.13.7}Varying A}{48}{subsubsection.16.13.7}
\contentsline {subsubsection}{\numberline {16.13.8}Varying Quant Noise}{49}{subsubsection.16.13.8}
